{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1i4CpsuOk3ZzpD28J0Tts5XtqjjMms9qN",
      "authorship_tag": "ABX9TyNQyyQCIrXWgFM+2OYwDive",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emaudealtema/Intelligence-Artificielle/blob/main/Bert_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k1_ZoVD0BEbZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = '../content/drive/MyDrive/Dataset/subjects-questions.csv'\n",
        "df = pd.read_csv(datapath)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y1HKi4jHBMBq",
        "outputId": "d1a9f37d-1b35-4122-dcd3-aaf7732c663e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 eng    Subject\n",
              "0  An anti-forest measure is\\nA. Afforestation\\nB...    Biology\n",
              "1  Among the following organic acids, the acid pr...  Chemistry\n",
              "2  If the area of two similar triangles are equal...      Maths\n",
              "3  In recent year, there has been a growing\\nconc...    Biology\n",
              "4  Which of the following statement\\nregarding tr...    Physics"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3675d2d7-180a-4b4f-8233-182190b84ab7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>Subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>An anti-forest measure is\\nA. Afforestation\\nB...</td>\n",
              "      <td>Biology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Among the following organic acids, the acid pr...</td>\n",
              "      <td>Chemistry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If the area of two similar triangles are equal...</td>\n",
              "      <td>Maths</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In recent year, there has been a growing\\nconc...</td>\n",
              "      <td>Biology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which of the following statement\\nregarding tr...</td>\n",
              "      <td>Physics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3675d2d7-180a-4b4f-8233-182190b84ab7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3675d2d7-180a-4b4f-8233-182190b84ab7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3675d2d7-180a-4b4f-8233-182190b84ab7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['Subject']).size().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "eie9dRcOBVIH",
        "outputId": "67210d34-cba9-407a-99b8-1c49ee144716"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff8eabac1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "6Lp06l4zBglf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "labels = {'business':0,\n",
        "          'entertainment':1,\n",
        "          'sport':2,\n",
        "          'tech':3,\n",
        "          'politics':4\n",
        "          }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['category']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "3K42OzhdBrZ2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvHLHT6QB0Fb",
        "outputId": "6802aa32-441a-4059-9d09-f0c9fc78e26c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98015 12252 12252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Les classes des donnees\n",
        "### Maintenant que nous savons quel type de sortie nous obtiendrons de BertTokenizer, construisons une classe Dataset pour notre jeu de données de nouvelles qui servira de classe pour générer nos données de nouvelles."
      ],
      "metadata": {
        "id": "NBLtOgQcEvZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "labels = {'Biology':0,\n",
        "          'Chemistry':1,\n",
        "          'Maths':2,\n",
        "          'Physics':3\n",
        "          \n",
        "          }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['Subject']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['eng']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "Hj037ZvDD5DH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après avoir défini la classe de l'ensemble de données, nous allons diviser notre cadre de données en ensembles de formation, de validation et de test avec la proportion de 80:10:10."
      ],
      "metadata": {
        "id": "XlYscOcIFu8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4RSgjLEFM65",
        "outputId": "136e2316-5578-45e4-e549-e121b162592d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98015 12252 12252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jusqu'à présent, nous avons construit une classe de jeu de données pour générer nos données. Maintenant, nous allons construire le modèle  en utilisant un modèle de base BERT pré-entraîné qui a 12 couches d'encodeur Transformer."
      ],
      "metadata": {
        "id": "IsJSGmzfGHVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.4):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768,4 )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "-Vre98YeF0Hg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle BERT produit deux variables :\n",
        "\n",
        "La première variable, que nous avons nommée _ dans le code ci-dessus, contient les vecteurs d'enchâssement de tous les tokens d'une séquence.\n",
        "La seconde variable, que nous avons nommée pooled_output, contient le vecteur d'enchâssement du token [CLS]. Pour une tâche de classification de texte, il suffit d'utiliser cet enchâssement comme entrée pour notre classifieur.\n",
        "Nous passons ensuite la variable pooled_output dans une couche linéaire avec une fonction d'activation ReLU. À la fin de la couche linéaire, nous avons un vecteur de taille 4, chacun correspondant à une catégorie de nos étiquettes (Biology, Physics, chimie, Math)."
      ],
      "metadata": {
        "id": "kjno3giCGjFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENtrainement du mod'le\n",
        "### l'entraînement sera une boucle d'entraînement standard de PyTorch."
      ],
      "metadata": {
        "id": "WIUFCauwHJkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "                  \n",
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "              \n",
        "train(model, df_train, df_val, LR, EPOCHS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "8WCyocvuGP-9",
        "outputId": "9491219e-4afc-4412-8330-270a7dbfe32a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  1%|          | 511/49008 [1:35:45<151:27:39, 11.24s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3a401a49635f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-3a401a49635f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2gkHtM5jHpKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous entraînons le modèle pendant 5 époques et nous utilisons Adam comme optimiseur(optimizer), tandis que le taux d'apprentissage(learning_rate) est fixé à 1e-6. Nous devons également utiliser l'entropie croisée catégorielle (categorical cross entropy ) comme fonction de perte puisque nous avons affaire à une classification multi-classes.\n",
        "\n",
        "j'utilise  GPU pour entraîner le modèle puisque le modèle de base de BERT contient 110 millions de paramètres.\n"
      ],
      "metadata": {
        "id": "-v1V5H4cLQmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Évaluation du modèle sur les données de test"
      ],
      "metadata": {
        "id": "5_bp2oKngzS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "    \n",
        "evaluate(model, df_test)"
      ],
      "metadata": {
        "id": "HOPEDkQbg95z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d3CeCQgChPBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}